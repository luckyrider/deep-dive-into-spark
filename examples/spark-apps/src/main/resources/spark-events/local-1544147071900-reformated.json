[
  {
    "Event": "SparkListenerLogStart",
    "Spark Version": "2.3.1"
  },
  {
    "Event": "SparkListenerExecutorAdded",
    "Timestamp": 1544147071936,
    "Executor ID": "driver",
    "Executor Info": {
      "Host": "localhost",
      "Total Cores": 8,
      "Log Urls": {}
    }
  },
  {
    "Event": "SparkListenerBlockManagerAdded",
    "Block Manager ID": {
      "Executor ID": "driver",
      "Host": "10.236.90.209",
      "Port": 50077
    },
    "Maximum Memory": 384093388,
    "Timestamp": 1544147071975,
    "Maximum Onheap Memory": 384093388,
    "Maximum Offheap Memory": 0
  },
  {
    "Event": "SparkListenerEnvironmentUpdate",
    "JVM Information": {
      "Java Home": "/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre",
      "Java Version": "1.8.0_131 (Oracle Corporation)",
      "Scala Version": "version 2.11.8"
    },
    "Spark Properties": {
      "spark.driver.host": "10.236.90.209",
      "spark.history.fs.logDirectory": "file:///Users/cmao/Workspace/deploy/spark-eventlog",
      "spark.sql.autoBroadcastJoinThreshold": "-1",
      "spark.eventLog.enabled": "true",
      "spark.driver.port": "50076",
      "spark.shuffle.service.enabled": "true",
      "spark.jars": "",
      "spark.yarn.historyServer.address": "localhost:18080",
      "spark.app.name": "SparkSQL::10.236.90.209",
      "spark.scheduler.mode": "FIFO",
      "spark.dynamicAllocation.maxExecutors": "1",
      "spark.executor.id": "driver",
      "spark.submit.deployMode": "client",
      "spark.master": "local[*]",
      "spark.executor.memory": "512m",
      "spark.eventLog.dir": "file:///Users/cmao/Workspace/deploy/spark-eventlog",
      "spark.dynamicAllocation.enabled": "true",
      "spark.sql.catalogImplementation": "hive",
      "spark.app.id": "local-1544147071900",
      "spark.sql.shuffle.partitions": "2"
    },
    "System Properties": {
      "java.io.tmpdir": "/var/folders/9_/fh3_gkzj5c593nl00hj54jnw395nt2/T/",
      "line.separator": "\n",
      "path.separator": ":",
      "sun.management.compiler": "HotSpot 64-Bit Tiered Compilers",
      "SPARK_SUBMIT": "true",
      "sun.cpu.endian": "little",
      "java.specification.version": "1.8",
      "java.vm.specification.name": "Java Virtual Machine Specification",
      "java.vendor": "Oracle Corporation",
      "java.vm.specification.version": "1.8",
      "user.home": "/Users/cmao",
      "file.encoding.pkg": "sun.io",
      "sun.nio.ch.bugLevel": "",
      "sun.arch.data.model": "64",
      "sun.boot.library.path": "/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/lib",
      "user.dir": "/Users/cmao",
      "java.library.path": "/Users/cmao/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.",
      "sun.cpu.isalist": "",
      "os.arch": "x86_64",
      "java.vm.version": "25.131-b11",
      "java.endorsed.dirs": "/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/lib/endorsed",
      "java.runtime.version": "1.8.0_131-b11",
      "java.vm.info": "mixed mode",
      "java.ext.dirs": "/Users/cmao/Library/Java/Extensions:/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/lib/ext:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java",
      "java.runtime.name": "Java(TM) SE Runtime Environment",
      "file.separator": "/",
      "java.class.version": "52.0",
      "java.specification.name": "Java Platform API Specification",
      "sun.boot.class.path": "/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/classes",
      "file.encoding": "UTF-8",
      "user.timezone": "Asia/Shanghai",
      "java.specification.vendor": "Oracle Corporation",
      "sun.java.launcher": "SUN_STANDARD",
      "os.version": "10.13.6",
      "sun.os.patch.level": "unknown",
      "gopherProxySet": "false",
      "java.vm.specification.vendor": "Oracle Corporation",
      "user.country": "US",
      "sun.jnu.encoding": "UTF-8",
      "user.language": "en",
      "java.vendor.url": "http://java.oracle.com/",
      "java.awt.printerjob": "sun.lwawt.macosx.CPrinterJob",
      "java.awt.graphicsenv": "sun.awt.CGraphicsEnvironment",
      "awt.toolkit": "sun.lwawt.macosx.LWCToolkit",
      "os.name": "Mac OS X",
      "java.vm.vendor": "Oracle Corporation",
      "java.vendor.url.bug": "http://bugreport.sun.com/bugreport/",
      "user.name": "cmao",
      "java.vm.name": "Java HotSpot(TM) 64-Bit Server VM",
      "sun.java.command": "org.apache.spark.deploy.SparkSubmit --conf spark.sql.autoBroadcastJoinThreshold=-1 --conf spark.sql.shuffle.partitions=2 --class org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver spark-internal",
      "java.home": "/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre",
      "java.version": "1.8.0_131",
      "sun.io.unicode.encoding": "UnicodeBig"
    },
    "Classpath Entries": {
      "/Users/cmao/Workspace/deploy/spark/jars/janino-3.0.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/stax-api-1.0.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-codec-1.10.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jackson-dataformat-yaml-2.6.7.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jackson-module-paranamer-2.7.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/metrics-json-3.1.5.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/machinist_2.11-0.6.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/metrics-graphite-3.1.5.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hadoop-yarn-api-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/gson-2.2.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/bcprov-jdk15on-1.58.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jackson-databind-2.6.7.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/javolution-5.5.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-math3-3.4.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hadoop-yarn-common-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-hive-thriftserver_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-yarn_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/compress-lzf-1.0.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/breeze-macros_2.11-0.13.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/datanucleus-api-jdo-3.2.6.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/kubernetes-model-2.0.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-logging-1.1.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-streaming_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/calcite-linq4j-1.2.0-incubating.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hadoop-auth-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jersey-client-2.22.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/kryo-shaded-3.0.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jodd-core-3.5.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jackson-module-jaxb-annotations-2.6.7.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/oro-2.0.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/scala-reflect-2.11.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/chill_2.11-0.8.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jackson-core-asl-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/pyrolite-4.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/avro-mapred-1.7.7-hadoop2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/base64-2.3.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/xercesImpl-2.9.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/kubernetes-client-3.0.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/apache-log4j-extras-1.2.17.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jackson-jaxrs-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/metrics-jvm-3.1.5.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-graphx_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spire_2.11-0.13.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/httpclient-4.5.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/xz-1.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hadoop-common-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jtransforms-2.4.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jackson-module-scala_2.11-2.6.7.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-hive_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/shapeless_2.11-2.3.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/spark-2.3.0-yarn-shuffle.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/datanucleus-core-3.2.10.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/curator-recipes-2.7.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hadoop-yarn-client-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jta-1.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/activation-1.1.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hadoop-mapreduce-client-jobclient-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/zstd-jni-1.3.2-2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/libthrift-0.9.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jpam-1.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hadoop-mapreduce-client-app-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-sql_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-io-2.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/zjsonpatch-0.3.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-compiler-3.0.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/parquet-jackson-1.8.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/generex-1.0.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/htrace-core-3.1.0-incubating.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/javax.ws.rs-api-2.0.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/metrics-core-3.1.5.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-catalyst_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/leveldbjni-all-1.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/orc-mapreduce-1.4.4-nohive.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-lang3-3.5.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jetty-util-6.1.26.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/antlr4-runtime-4.7.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/javax.annotation-api-1.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/arrow-vector-0.8.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jersey-server-2.22.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/curator-framework-2.7.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-mllib-local_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/stringtemplate-3.2.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/core-1.1.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/json4s-jackson_2.11-3.2.11.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/scala-compiler-2.11.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/aopalliance-repackaged-2.4.0-b34.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jul-to-slf4j-1.7.16.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/lz4-java-1.4.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/json4s-ast_2.11-3.2.11.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jetty-6.1.26.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/osgi-resource-locator-1.0.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-repl_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hadoop-mapreduce-client-core-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hadoop-yarn-server-common-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/slf4j-log4j12-1.7.16.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/arrow-format-0.8.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jersey-media-jaxb-2.22.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/parquet-column-1.8.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/snappy-java-1.1.2.6.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hive-beeline-1.2.1.spark2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/logging-interceptor-3.8.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-lang-2.6.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hk2-utils-2.4.0-b34.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/aopalliance-1.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/snakeyaml-1.15.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jsr305-1.3.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/guava-14.0.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/breeze_2.11-0.13.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/opencsv-2.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/httpcore-4.4.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/snappy-0.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/calcite-core-1.2.0-incubating.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/javax.inject-1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/JavaEWAH-0.3.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/eigenbase-properties-1.1.5.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jline-2.12.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-kubernetes_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/chill-java-0.8.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-digester-1.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-httpclient-3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/scala-library-2.11.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/slf4j-api-1.7.16.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar": "System Classpath",
      "/Users/cmao/Workspace/dataplatform/deploy/hadoop-conf": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-launcher_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/libfb303-0.9.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/guice-3.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/minlog-1.3.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-core_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hadoop-client-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/protobuf-java-2.5.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/netty-all-4.1.17.Final.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/log4j-1.2.17.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/netty-3.9.9.Final.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jets3t-0.9.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/arrow-memory-0.8.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jcl-over-slf4j-1.7.16.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/automaton-1.11-8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/stax-api-1.0-2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/aircompressor-0.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-tags_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-dbcp-1.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spire-macros_2.11-0.13.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/parquet-format-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/RoaringBitmap-0.5.11.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/univocity-parsers-2.5.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-unsafe_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/api-util-1.0.0-M20.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-conf/": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-kvstore_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/zookeeper-3.4.6.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-cli-1.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/avro-ipc-1.7.7.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-network-shuffle_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/parquet-hadoop-1.8.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/javassist-3.18.1-GA.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/okio-1.13.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hadoop-hdfs-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/json4s-core_2.11-3.2.11.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hk2-api-2.4.0-b34.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-beanutils-1.7.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/scala-parser-combinators_2.11-1.0.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/calcite-avatica-1.2.0-incubating.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hadoop-annotations-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/macro-compat_2.11-1.1.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jackson-annotations-2.6.7.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/validation-api-1.1.0.Final.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/paranamer-2.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jdo-api-3.0.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/antlr-runtime-3.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/super-csv-2.2.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/arpack_combined_all-0.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/parquet-common-1.8.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jersey-guava-2.22.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/avro-1.7.7.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hadoop-yarn-server-web-proxy-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/xbean-asm5-shaded-4.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/mesos-1.4.0-shaded-protobuf.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jersey-container-servlet-2.22.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/derby-10.12.1.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/okhttp-3.8.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-beanutils-core-1.8.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-mesos_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-pool-1.5.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop/contrib/capacity-scheduler/*.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/guice-servlet-3.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hadoop-mapreduce-client-common-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hive-conf/": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-mllib_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/bonecp-0.8.0.RELEASE.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-sketch_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hive-exec-1.2.1.spark2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/curator-client-2.7.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/joda-time-2.9.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/orc-core-1.4.4-nohive.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/javax.servlet-api-3.1.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-compress-1.4.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jersey-container-servlet-core-2.22.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/api-asn1-api-1.0.0-M20.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-crypto-1.0.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/py4j-0.10.7.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/parquet-encoding-1.8.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark-conf/": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/objenesis-2.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/java-xmlbuilder-1.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/scala-xml_2.11-1.0.5.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/apacheds-i18n-2.0.0-M15.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/xmlenc-0.52.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jaxb-api-2.2.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jackson-mapper-asl-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jersey-common-2.22.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/antlr-2.7.7.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/stream-2.7.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hadoop-mapreduce-client-shuffle-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/ivy-2.4.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hk2-locator-2.4.0-b34.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/apacheds-kerberos-codec-2.0.0-M15.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/datanucleus-rdbms-3.2.9.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/scalap-2.11.8.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jsp-api-2.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hive-cli-1.2.1.spark2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-net-2.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/flatbuffers-1.2.0-3f79e055.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/parquet-hadoop-bundle-1.6.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/ST4-4.0.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hppc-0.7.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hive-metastore-1.2.1.spark2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jackson-core-2.6.7.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/hive-jdbc-1.2.1.spark2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-collections-3.2.2.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/javax.inject-2.4.0-b34.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/commons-configuration-1.6.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/spark-network-common_2.11-2.3.1.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/spark/jars/jackson-xc-1.9.13.jar": "System Classpath",
      "/Users/cmao/Workspace/deploy/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar": "System Classpath"
    }
  },
  {
    "Event": "SparkListenerApplicationStart",
    "App Name": "SparkSQL::10.236.90.209",
    "App ID": "local-1544147071900",
    "Timestamp": 1544147071215,
    "User": "cmao"
  },
  {
    "Event": "org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart",
    "executionId": 0,
    "description": "processCmd at CliDriver.java:376",
    "details": "org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:364)\norg.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:272)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)",
    "physicalPlanDescription": "== Parsed Logical Plan ==\nProject [id#0, name#1, school#7]\n+- Join Inner, (graduate_program#2 = id#4)\n   :- SubqueryAlias p\n   :  +- SubqueryAlias person\n   :     +- Relation[id#0,name#1,graduate_program#2,spark_status#3] parquet\n   +- SubqueryAlias gp\n      +- SubqueryAlias graduate_program\n         +- Relation[id#4,degree#5,department#6,school#7] parquet\n\n== Analyzed Logical Plan ==\nid: int, name: string, school: string\nProject [id#0, name#1, school#7]\n+- Join Inner, (graduate_program#2 = id#4)\n   :- SubqueryAlias p\n   :  +- SubqueryAlias person\n   :     +- Relation[id#0,name#1,graduate_program#2,spark_status#3] parquet\n   +- SubqueryAlias gp\n      +- SubqueryAlias graduate_program\n         +- Relation[id#4,degree#5,department#6,school#7] parquet\n\n== Optimized Logical Plan ==\nProject [id#0, name#1, school#7]\n+- Join Inner, (graduate_program#2 = id#4)\n   :- Project [id#0, name#1, graduate_program#2]\n   :  +- Filter isnotnull(graduate_program#2)\n   :     +- Relation[id#0,name#1,graduate_program#2,spark_status#3] parquet\n   +- Project [id#4, school#7]\n      +- Filter isnotnull(id#4)\n         +- Relation[id#4,degree#5,department#6,school#7] parquet\n\n== Physical Plan ==\n*(5) Project [id#0, name#1, school#7]\n+- *(5) SortMergeJoin [graduate_program#2], [id#4], Inner\n   :- *(2) Sort [graduate_program#2 ASC NULLS FIRST], false, 0\n   :  +- Exchange hashpartitioning(graduate_program#2, 2)\n   :     +- *(1) Project [id#0, name#1, graduate_program#2]\n   :        +- *(1) Filter isnotnull(graduate_program#2)\n   :           +- *(1) FileScan parquet default.person[id#0,name#1,graduate_program#2] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/user/hive/warehouse/person], PartitionFilters: [], PushedFilters: [IsNotNull(graduate_program)], ReadSchema: struct<id:int,name:string,graduate_program:int>\n   +- *(4) Sort [id#4 ASC NULLS FIRST], false, 0\n      +- Exchange hashpartitioning(id#4, 2)\n         +- *(3) Project [id#4, school#7]\n            +- *(3) Filter isnotnull(id#4)\n               +- *(3) FileScan parquet default.graduate_program[id#4,school#7] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/user/hive/warehouse/graduate_program], PartitionFilters: [], PushedFilters: [IsNotNull(id)], ReadSchema: struct<id:int,school:string>",
    "sparkPlanInfo": {
      "nodeName": "WholeStageCodegen",
      "simpleString": "WholeStageCodegen",
      "children": [
        {
          "nodeName": "Project",
          "simpleString": "Project [id#0, name#1, school#7]",
          "children": [
            {
              "nodeName": "SortMergeJoin",
              "simpleString": "SortMergeJoin [graduate_program#2], [id#4], Inner",
              "children": [
                {
                  "nodeName": "InputAdapter",
                  "simpleString": "InputAdapter",
                  "children": [
                    {
                      "nodeName": "WholeStageCodegen",
                      "simpleString": "WholeStageCodegen",
                      "children": [
                        {
                          "nodeName": "Sort",
                          "simpleString": "Sort [graduate_program#2 ASC NULLS FIRST], false, 0",
                          "children": [
                            {
                              "nodeName": "InputAdapter",
                              "simpleString": "InputAdapter",
                              "children": [
                                {
                                  "nodeName": "Exchange",
                                  "simpleString": "Exchange hashpartitioning(graduate_program#2, 2)",
                                  "children": [
                                    {
                                      "nodeName": "WholeStageCodegen",
                                      "simpleString": "WholeStageCodegen",
                                      "children": [
                                        {
                                          "nodeName": "Project",
                                          "simpleString": "Project [id#0, name#1, graduate_program#2]",
                                          "children": [
                                            {
                                              "nodeName": "Filter",
                                              "simpleString": "Filter isnotnull(graduate_program#2)",
                                              "children": [
                                                {
                                                  "nodeName": "Scan parquet default.person",
                                                  "simpleString": "FileScan parquet default.person[id#0,name#1,graduate_program#2] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/user/hive/warehouse/person], PartitionFilters: [], PushedFilters: [IsNotNull(graduate_program)], ReadSchema: struct<id:int,name:string,graduate_program:int>",
                                                  "children": [],
                                                  "metrics": [
                                                    {
                                                      "name": "number of output rows",
                                                      "accumulatorId": 12,
                                                      "metricType": "sum"
                                                    },
                                                    {
                                                      "name": "number of files",
                                                      "accumulatorId": 13,
                                                      "metricType": "sum"
                                                    },
                                                    {
                                                      "name": "metadata time (ms)",
                                                      "accumulatorId": 14,
                                                      "metricType": "sum"
                                                    },
                                                    {
                                                      "name": "scan time total (min, med, max)",
                                                      "accumulatorId": 15,
                                                      "metricType": "timing"
                                                    }
                                                  ]
                                                }
                                              ],
                                              "metrics": [
                                                {
                                                  "name": "number of output rows",
                                                  "accumulatorId": 11,
                                                  "metricType": "sum"
                                                }
                                              ]
                                            }
                                          ],
                                          "metrics": []
                                        }
                                      ],
                                      "metrics": [
                                        {
                                          "name": "duration total (min, med, max)",
                                          "accumulatorId": 10,
                                          "metricType": "timing"
                                        }
                                      ]
                                    }
                                  ],
                                  "metrics": [
                                    {
                                      "name": "data size total (min, med, max)",
                                      "accumulatorId": 2,
                                      "metricType": "size"
                                    }
                                  ]
                                }
                              ],
                              "metrics": []
                            }
                          ],
                          "metrics": [
                            {
                              "name": "sort time total (min, med, max)",
                              "accumulatorId": 7,
                              "metricType": "timing"
                            },
                            {
                              "name": "peak memory total (min, med, max)",
                              "accumulatorId": 8,
                              "metricType": "size"
                            },
                            {
                              "name": "spill size total (min, med, max)",
                              "accumulatorId": 9,
                              "metricType": "size"
                            }
                          ]
                        }
                      ],
                      "metrics": [
                        {
                          "name": "duration total (min, med, max)",
                          "accumulatorId": 6,
                          "metricType": "timing"
                        }
                      ]
                    }
                  ],
                  "metrics": []
                },
                {
                  "nodeName": "InputAdapter",
                  "simpleString": "InputAdapter",
                  "children": [
                    {
                      "nodeName": "WholeStageCodegen",
                      "simpleString": "WholeStageCodegen",
                      "children": [
                        {
                          "nodeName": "Sort",
                          "simpleString": "Sort [id#4 ASC NULLS FIRST], false, 0",
                          "children": [
                            {
                              "nodeName": "InputAdapter",
                              "simpleString": "InputAdapter",
                              "children": [
                                {
                                  "nodeName": "Exchange",
                                  "simpleString": "Exchange hashpartitioning(id#4, 2)",
                                  "children": [
                                    {
                                      "nodeName": "WholeStageCodegen",
                                      "simpleString": "WholeStageCodegen",
                                      "children": [
                                        {
                                          "nodeName": "Project",
                                          "simpleString": "Project [id#4, school#7]",
                                          "children": [
                                            {
                                              "nodeName": "Filter",
                                              "simpleString": "Filter isnotnull(id#4)",
                                              "children": [
                                                {
                                                  "nodeName": "Scan parquet default.graduate_program",
                                                  "simpleString": "FileScan parquet default.graduate_program[id#4,school#7] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/user/hive/warehouse/graduate_program], PartitionFilters: [], PushedFilters: [IsNotNull(id)], ReadSchema: struct<id:int,school:string>",
                                                  "children": [],
                                                  "metrics": [
                                                    {
                                                      "name": "number of output rows",
                                                      "accumulatorId": 22,
                                                      "metricType": "sum"
                                                    },
                                                    {
                                                      "name": "number of files",
                                                      "accumulatorId": 23,
                                                      "metricType": "sum"
                                                    },
                                                    {
                                                      "name": "metadata time (ms)",
                                                      "accumulatorId": 24,
                                                      "metricType": "sum"
                                                    },
                                                    {
                                                      "name": "scan time total (min, med, max)",
                                                      "accumulatorId": 25,
                                                      "metricType": "timing"
                                                    }
                                                  ]
                                                }
                                              ],
                                              "metrics": [
                                                {
                                                  "name": "number of output rows",
                                                  "accumulatorId": 21,
                                                  "metricType": "sum"
                                                }
                                              ]
                                            }
                                          ],
                                          "metrics": []
                                        }
                                      ],
                                      "metrics": [
                                        {
                                          "name": "duration total (min, med, max)",
                                          "accumulatorId": 20,
                                          "metricType": "timing"
                                        }
                                      ]
                                    }
                                  ],
                                  "metrics": [
                                    {
                                      "name": "data size total (min, med, max)",
                                      "accumulatorId": 3,
                                      "metricType": "size"
                                    }
                                  ]
                                }
                              ],
                              "metrics": []
                            }
                          ],
                          "metrics": [
                            {
                              "name": "sort time total (min, med, max)",
                              "accumulatorId": 17,
                              "metricType": "timing"
                            },
                            {
                              "name": "peak memory total (min, med, max)",
                              "accumulatorId": 18,
                              "metricType": "size"
                            },
                            {
                              "name": "spill size total (min, med, max)",
                              "accumulatorId": 19,
                              "metricType": "size"
                            }
                          ]
                        }
                      ],
                      "metrics": [
                        {
                          "name": "duration total (min, med, max)",
                          "accumulatorId": 16,
                          "metricType": "timing"
                        }
                      ]
                    }
                  ],
                  "metrics": []
                }
              ],
              "metrics": [
                {
                  "name": "number of output rows",
                  "accumulatorId": 5,
                  "metricType": "sum"
                }
              ]
            }
          ],
          "metrics": []
        }
      ],
      "metrics": [
        {
          "name": "duration total (min, med, max)",
          "accumulatorId": 4,
          "metricType": "timing"
        }
      ]
    },
    "time": 1544147163440
  },
  {
    "Event": "org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates",
    "executionId": 0,
    "accumUpdates": [
      [
        13,
        2
      ],
      [
        14,
        4
      ]
    ]
  },
  {
    "Event": "org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates",
    "executionId": 0,
    "accumUpdates": [
      [
        23,
        2
      ],
      [
        24,
        0
      ]
    ]
  },
  {
    "Event": "SparkListenerJobStart",
    "Job ID": 0,
    "Submission Time": 1544147164379,
    "Stage Infos": [
      {
        "Stage ID": 0,
        "Stage Attempt ID": 0,
        "Stage Name": "processCmd at CliDriver.java:376",
        "Number of Tasks": 2,
        "RDD Info": [
          {
            "RDD ID": 2,
            "Name": "MapPartitionsRDD",
            "Scope": "{\"id\":\"7\",\"name\":\"Exchange\"}",
            "Callsite": "processCmd at CliDriver.java:376",
            "Parent IDs": [
              1
            ],
            "Storage Level": {
              "Use Disk": false,
              "Use Memory": false,
              "Deserialized": false,
              "Replication": 1
            },
            "Number of Partitions": 2,
            "Number of Cached Partitions": 0,
            "Memory Size": 0,
            "Disk Size": 0
          },
          {
            "RDD ID": 1,
            "Name": "MapPartitionsRDD",
            "Scope": "{\"id\":\"8\",\"name\":\"WholeStageCodegen\"}",
            "Callsite": "processCmd at CliDriver.java:376",
            "Parent IDs": [
              0
            ],
            "Storage Level": {
              "Use Disk": false,
              "Use Memory": false,
              "Deserialized": false,
              "Replication": 1
            },
            "Number of Partitions": 2,
            "Number of Cached Partitions": 0,
            "Memory Size": 0,
            "Disk Size": 0
          },
          {
            "RDD ID": 0,
            "Name": "FileScanRDD",
            "Scope": "{\"id\":\"8\",\"name\":\"WholeStageCodegen\"}",
            "Callsite": "processCmd at CliDriver.java:376",
            "Parent IDs": [],
            "Storage Level": {
              "Use Disk": false,
              "Use Memory": false,
              "Deserialized": false,
              "Replication": 1
            },
            "Number of Partitions": 2,
            "Number of Cached Partitions": 0,
            "Memory Size": 0,
            "Disk Size": 0
          }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:364)\norg.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:272)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)",
        "Accumulables": []
      },
      {
        "Stage ID": 1,
        "Stage Attempt ID": 0,
        "Stage Name": "processCmd at CliDriver.java:376",
        "Number of Tasks": 2,
        "RDD Info": [
          {
            "RDD ID": 7,
            "Name": "MapPartitionsRDD",
            "Scope": "{\"id\":\"16\",\"name\":\"Exchange\"}",
            "Callsite": "processCmd at CliDriver.java:376",
            "Parent IDs": [
              6
            ],
            "Storage Level": {
              "Use Disk": false,
              "Use Memory": false,
              "Deserialized": false,
              "Replication": 1
            },
            "Number of Partitions": 2,
            "Number of Cached Partitions": 0,
            "Memory Size": 0,
            "Disk Size": 0
          },
          {
            "RDD ID": 5,
            "Name": "FileScanRDD",
            "Scope": "{\"id\":\"17\",\"name\":\"WholeStageCodegen\"}",
            "Callsite": "processCmd at CliDriver.java:376",
            "Parent IDs": [],
            "Storage Level": {
              "Use Disk": false,
              "Use Memory": false,
              "Deserialized": false,
              "Replication": 1
            },
            "Number of Partitions": 2,
            "Number of Cached Partitions": 0,
            "Memory Size": 0,
            "Disk Size": 0
          },
          {
            "RDD ID": 6,
            "Name": "MapPartitionsRDD",
            "Scope": "{\"id\":\"17\",\"name\":\"WholeStageCodegen\"}",
            "Callsite": "processCmd at CliDriver.java:376",
            "Parent IDs": [
              5
            ],
            "Storage Level": {
              "Use Disk": false,
              "Use Memory": false,
              "Deserialized": false,
              "Replication": 1
            },
            "Number of Partitions": 2,
            "Number of Cached Partitions": 0,
            "Memory Size": 0,
            "Disk Size": 0
          }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:364)\norg.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:272)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)",
        "Accumulables": []
      },
      {
        "Stage ID": 2,
        "Stage Attempt ID": 0,
        "Stage Name": "processCmd at CliDriver.java:376",
        "Number of Tasks": 2,
        "RDD Info": [
          {
            "RDD ID": 12,
            "Name": "MapPartitionsRDD",
            "Scope": "{\"id\":\"21\",\"name\":\"mapPartitionsInternal\"}",
            "Callsite": "processCmd at CliDriver.java:376",
            "Parent IDs": [
              11
            ],
            "Storage Level": {
              "Use Disk": false,
              "Use Memory": false,
              "Deserialized": false,
              "Replication": 1
            },
            "Number of Partitions": 2,
            "Number of Cached Partitions": 0,
            "Memory Size": 0,
            "Disk Size": 0
          },
          {
            "RDD ID": 4,
            "Name": "MapPartitionsRDD",
            "Scope": "{\"id\":\"4\",\"name\":\"WholeStageCodegen\"}",
            "Callsite": "processCmd at CliDriver.java:376",
            "Parent IDs": [
              3
            ],
            "Storage Level": {
              "Use Disk": false,
              "Use Memory": false,
              "Deserialized": false,
              "Replication": 1
            },
            "Number of Partitions": 2,
            "Number of Cached Partitions": 0,
            "Memory Size": 0,
            "Disk Size": 0
          },
          {
            "RDD ID": 9,
            "Name": "MapPartitionsRDD",
            "Scope": "{\"id\":\"13\",\"name\":\"WholeStageCodegen\"}",
            "Callsite": "processCmd at CliDriver.java:376",
            "Parent IDs": [
              8
            ],
            "Storage Level": {
              "Use Disk": false,
              "Use Memory": false,
              "Deserialized": false,
              "Replication": 1
            },
            "Number of Partitions": 2,
            "Number of Cached Partitions": 0,
            "Memory Size": 0,
            "Disk Size": 0
          },
          {
            "RDD ID": 8,
            "Name": "ShuffledRowRDD",
            "Scope": "{\"id\":\"16\",\"name\":\"Exchange\"}",
            "Callsite": "processCmd at CliDriver.java:376",
            "Parent IDs": [
              7
            ],
            "Storage Level": {
              "Use Disk": false,
              "Use Memory": false,
              "Deserialized": false,
              "Replication": 1
            },
            "Number of Partitions": 2,
            "Number of Cached Partitions": 0,
            "Memory Size": 0,
            "Disk Size": 0
          },
          {
            "RDD ID": 10,
            "Name": "ZippedPartitionsRDD2",
            "Scope": "{\"id\":\"0\",\"name\":\"WholeStageCodegen\"}",
            "Callsite": "processCmd at CliDriver.java:376",
            "Parent IDs": [
              4,
              9
            ],
            "Storage Level": {
              "Use Disk": false,
              "Use Memory": false,
              "Deserialized": false,
              "Replication": 1
            },
            "Number of Partitions": 2,
            "Number of Cached Partitions": 0,
            "Memory Size": 0,
            "Disk Size": 0
          },
          {
            "RDD ID": 11,
            "Name": "MapPartitionsRDD",
            "Scope": "{\"id\":\"0\",\"name\":\"WholeStageCodegen\"}",
            "Callsite": "processCmd at CliDriver.java:376",
            "Parent IDs": [
              10
            ],
            "Storage Level": {
              "Use Disk": false,
              "Use Memory": false,
              "Deserialized": false,
              "Replication": 1
            },
            "Number of Partitions": 2,
            "Number of Cached Partitions": 0,
            "Memory Size": 0,
            "Disk Size": 0
          },
          {
            "RDD ID": 3,
            "Name": "ShuffledRowRDD",
            "Scope": "{\"id\":\"7\",\"name\":\"Exchange\"}",
            "Callsite": "processCmd at CliDriver.java:376",
            "Parent IDs": [
              2
            ],
            "Storage Level": {
              "Use Disk": false,
              "Use Memory": false,
              "Deserialized": false,
              "Replication": 1
            },
            "Number of Partitions": 2,
            "Number of Cached Partitions": 0,
            "Memory Size": 0,
            "Disk Size": 0
          }
        ],
        "Parent IDs": [
          0,
          1
        ],
        "Details": "org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:364)\norg.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:272)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)",
        "Accumulables": []
      }
    ],
    "Stage IDs": [
      0,
      1,
      2
    ],
    "Properties": {
      "spark.rdd.scope.noOverride": "true",
      "spark.rdd.scope": "{\"id\":\"22\",\"name\":\"collect\"}",
      "spark.sql.execution.id": "0",
      "spark.job.description": "select p.id, p.name, gp.school from person p join graduate_program gp on p.graduate_program = gp.id"
    }
  },
  {
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
      "Stage ID": 0,
      "Stage Attempt ID": 0,
      "Stage Name": "processCmd at CliDriver.java:376",
      "Number of Tasks": 2,
      "RDD Info": [
        {
          "RDD ID": 2,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"7\",\"name\":\"Exchange\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            1
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 1,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"8\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            0
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 0,
          "Name": "FileScanRDD",
          "Scope": "{\"id\":\"8\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        }
      ],
      "Parent IDs": [],
      "Details": "org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:364)\norg.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:272)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)",
      "Submission Time": 1544147164396,
      "Accumulables": []
    },
    "Properties": {
      "spark.rdd.scope.noOverride": "true",
      "spark.rdd.scope": "{\"id\":\"22\",\"name\":\"collect\"}",
      "spark.sql.execution.id": "0",
      "spark.job.description": "select p.id, p.name, gp.school from person p join graduate_program gp on p.graduate_program = gp.id"
    }
  },
  {
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
      "Stage ID": 1,
      "Stage Attempt ID": 0,
      "Stage Name": "processCmd at CliDriver.java:376",
      "Number of Tasks": 2,
      "RDD Info": [
        {
          "RDD ID": 7,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"16\",\"name\":\"Exchange\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            6
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 5,
          "Name": "FileScanRDD",
          "Scope": "{\"id\":\"17\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 6,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"17\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            5
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        }
      ],
      "Parent IDs": [],
      "Details": "org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:364)\norg.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:272)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)",
      "Submission Time": 1544147164430,
      "Accumulables": []
    },
    "Properties": {
      "spark.rdd.scope.noOverride": "true",
      "spark.rdd.scope": "{\"id\":\"22\",\"name\":\"collect\"}",
      "spark.sql.execution.id": "0",
      "spark.job.description": "select p.id, p.name, gp.school from person p join graduate_program gp on p.graduate_program = gp.id"
    }
  },
  {
    "Event": "SparkListenerTaskStart",
    "Stage ID": 0,
    "Stage Attempt ID": 0,
    "Task Info": {
      "Task ID": 0,
      "Index": 0,
      "Attempt": 0,
      "Launch Time": 1544147164441,
      "Executor ID": "driver",
      "Host": "localhost",
      "Locality": "PROCESS_LOCAL",
      "Speculative": false,
      "Getting Result Time": 0,
      "Finish Time": 0,
      "Failed": false,
      "Killed": false,
      "Accumulables": []
    }
  },
  {
    "Event": "SparkListenerTaskStart",
    "Stage ID": 0,
    "Stage Attempt ID": 0,
    "Task Info": {
      "Task ID": 1,
      "Index": 1,
      "Attempt": 0,
      "Launch Time": 1544147164451,
      "Executor ID": "driver",
      "Host": "localhost",
      "Locality": "PROCESS_LOCAL",
      "Speculative": false,
      "Getting Result Time": 0,
      "Finish Time": 0,
      "Failed": false,
      "Killed": false,
      "Accumulables": []
    }
  },
  {
    "Event": "SparkListenerTaskStart",
    "Stage ID": 1,
    "Stage Attempt ID": 0,
    "Task Info": {
      "Task ID": 2,
      "Index": 0,
      "Attempt": 0,
      "Launch Time": 1544147164458,
      "Executor ID": "driver",
      "Host": "localhost",
      "Locality": "PROCESS_LOCAL",
      "Speculative": false,
      "Getting Result Time": 0,
      "Finish Time": 0,
      "Failed": false,
      "Killed": false,
      "Accumulables": []
    }
  },
  {
    "Event": "SparkListenerTaskStart",
    "Stage ID": 1,
    "Stage Attempt ID": 0,
    "Task Info": {
      "Task ID": 3,
      "Index": 1,
      "Attempt": 0,
      "Launch Time": 1544147164458,
      "Executor ID": "driver",
      "Host": "localhost",
      "Locality": "PROCESS_LOCAL",
      "Speculative": false,
      "Getting Result Time": 0,
      "Finish Time": 0,
      "Failed": false,
      "Killed": false,
      "Accumulables": []
    }
  },
  {
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 1,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
      "Reason": "Success"
    },
    "Task Info": {
      "Task ID": 3,
      "Index": 1,
      "Attempt": 0,
      "Launch Time": 1544147164458,
      "Executor ID": "driver",
      "Host": "localhost",
      "Locality": "PROCESS_LOCAL",
      "Speculative": false,
      "Getting Result Time": 0,
      "Finish Time": 1544147164878,
      "Failed": false,
      "Killed": false,
      "Accumulables": [
        {
          "ID": 3,
          "Name": "data size total (min, med, max)",
          "Update": "39",
          "Value": "38",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 21,
          "Name": "number of output rows",
          "Update": "1",
          "Value": "1",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 25,
          "Name": "scan time total (min, med, max)",
          "Update": "254",
          "Value": "253",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 22,
          "Name": "number of output rows",
          "Update": "1",
          "Value": "1",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 20,
          "Name": "duration total (min, med, max)",
          "Update": "296",
          "Value": "295",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 73,
          "Name": "internal.metrics.input.recordsRead",
          "Update": 1,
          "Value": 1,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 72,
          "Name": "internal.metrics.input.bytesRead",
          "Update": 2465,
          "Value": 2465,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 71,
          "Name": "internal.metrics.shuffle.write.writeTime",
          "Update": 19135424,
          "Value": 19135424,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 70,
          "Name": "internal.metrics.shuffle.write.recordsWritten",
          "Update": 1,
          "Value": 1,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 69,
          "Name": "internal.metrics.shuffle.write.bytesWritten",
          "Update": 80,
          "Value": 80,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 57,
          "Name": "internal.metrics.resultSerializationTime",
          "Update": 1,
          "Value": 1,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 55,
          "Name": "internal.metrics.resultSize",
          "Update": 1628,
          "Value": 1628,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 54,
          "Name": "internal.metrics.executorCpuTime",
          "Update": 197164000,
          "Value": 197164000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 53,
          "Name": "internal.metrics.executorRunTime",
          "Update": 379,
          "Value": 379,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 52,
          "Name": "internal.metrics.executorDeserializeCpuTime",
          "Update": 11139000,
          "Value": 11139000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 51,
          "Name": "internal.metrics.executorDeserializeTime",
          "Update": 25,
          "Value": 25,
          "Internal": true,
          "Count Failed Values": true
        }
      ]
    },
    "Task Metrics": {
      "Executor Deserialize Time": 25,
      "Executor Deserialize CPU Time": 11139000,
      "Executor Run Time": 379,
      "Executor CPU Time": 197164000,
      "Result Size": 1628,
      "JVM GC Time": 0,
      "Result Serialization Time": 1,
      "Memory Bytes Spilled": 0,
      "Disk Bytes Spilled": 0,
      "Shuffle Read Metrics": {
        "Remote Blocks Fetched": 0,
        "Local Blocks Fetched": 0,
        "Fetch Wait Time": 0,
        "Remote Bytes Read": 0,
        "Remote Bytes Read To Disk": 0,
        "Local Bytes Read": 0,
        "Total Records Read": 0
      },
      "Shuffle Write Metrics": {
        "Shuffle Bytes Written": 80,
        "Shuffle Write Time": 19135424,
        "Shuffle Records Written": 1
      },
      "Input Metrics": {
        "Bytes Read": 2465,
        "Records Read": 1
      },
      "Output Metrics": {
        "Bytes Written": 0,
        "Records Written": 0
      },
      "Updated Blocks": []
    }
  },
  {
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 0,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
      "Reason": "Success"
    },
    "Task Info": {
      "Task ID": 0,
      "Index": 0,
      "Attempt": 0,
      "Launch Time": 1544147164441,
      "Executor ID": "driver",
      "Host": "localhost",
      "Locality": "PROCESS_LOCAL",
      "Speculative": false,
      "Getting Result Time": 0,
      "Finish Time": 1544147164881,
      "Failed": false,
      "Killed": false,
      "Accumulables": [
        {
          "ID": 2,
          "Name": "data size total (min, med, max)",
          "Update": "95",
          "Value": "94",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 11,
          "Name": "number of output rows",
          "Update": "2",
          "Value": "2",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 15,
          "Name": "scan time total (min, med, max)",
          "Update": "254",
          "Value": "253",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 12,
          "Name": "number of output rows",
          "Update": "2",
          "Value": "2",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 10,
          "Name": "duration total (min, med, max)",
          "Update": "298",
          "Value": "297",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 48,
          "Name": "internal.metrics.input.recordsRead",
          "Update": 2,
          "Value": 2,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 47,
          "Name": "internal.metrics.input.bytesRead",
          "Update": 2391,
          "Value": 2391,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 46,
          "Name": "internal.metrics.shuffle.write.writeTime",
          "Update": 20845542,
          "Value": 20845542,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 45,
          "Name": "internal.metrics.shuffle.write.recordsWritten",
          "Update": 2,
          "Value": 2,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 44,
          "Name": "internal.metrics.shuffle.write.bytesWritten",
          "Update": 105,
          "Value": 105,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 32,
          "Name": "internal.metrics.resultSerializationTime",
          "Update": 2,
          "Value": 2,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 30,
          "Name": "internal.metrics.resultSize",
          "Update": 1628,
          "Value": 1628,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 29,
          "Name": "internal.metrics.executorCpuTime",
          "Update": 107908000,
          "Value": 107908000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 28,
          "Name": "internal.metrics.executorRunTime",
          "Update": 379,
          "Value": 379,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 27,
          "Name": "internal.metrics.executorDeserializeCpuTime",
          "Update": 22149000,
          "Value": 22149000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 26,
          "Name": "internal.metrics.executorDeserializeTime",
          "Update": 27,
          "Value": 27,
          "Internal": true,
          "Count Failed Values": true
        }
      ]
    },
    "Task Metrics": {
      "Executor Deserialize Time": 27,
      "Executor Deserialize CPU Time": 22149000,
      "Executor Run Time": 379,
      "Executor CPU Time": 107908000,
      "Result Size": 1628,
      "JVM GC Time": 0,
      "Result Serialization Time": 2,
      "Memory Bytes Spilled": 0,
      "Disk Bytes Spilled": 0,
      "Shuffle Read Metrics": {
        "Remote Blocks Fetched": 0,
        "Local Blocks Fetched": 0,
        "Fetch Wait Time": 0,
        "Remote Bytes Read": 0,
        "Remote Bytes Read To Disk": 0,
        "Local Bytes Read": 0,
        "Total Records Read": 0
      },
      "Shuffle Write Metrics": {
        "Shuffle Bytes Written": 105,
        "Shuffle Write Time": 20845542,
        "Shuffle Records Written": 2
      },
      "Input Metrics": {
        "Bytes Read": 2391,
        "Records Read": 2
      },
      "Output Metrics": {
        "Bytes Written": 0,
        "Records Written": 0
      },
      "Updated Blocks": []
    }
  },
  {
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 1,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
      "Reason": "Success"
    },
    "Task Info": {
      "Task ID": 2,
      "Index": 0,
      "Attempt": 0,
      "Launch Time": 1544147164458,
      "Executor ID": "driver",
      "Host": "localhost",
      "Locality": "PROCESS_LOCAL",
      "Speculative": false,
      "Getting Result Time": 0,
      "Finish Time": 1544147164881,
      "Failed": false,
      "Killed": false,
      "Accumulables": [
        {
          "ID": 3,
          "Name": "data size total (min, med, max)",
          "Update": "79",
          "Value": "117",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 21,
          "Name": "number of output rows",
          "Update": "2",
          "Value": "3",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 25,
          "Name": "scan time total (min, med, max)",
          "Update": "254",
          "Value": "507",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 22,
          "Name": "number of output rows",
          "Update": "2",
          "Value": "3",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 20,
          "Name": "duration total (min, med, max)",
          "Update": "296",
          "Value": "591",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 73,
          "Name": "internal.metrics.input.recordsRead",
          "Update": 2,
          "Value": 3,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 72,
          "Name": "internal.metrics.input.bytesRead",
          "Update": 2250,
          "Value": 4715,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 71,
          "Name": "internal.metrics.shuffle.write.writeTime",
          "Update": 19888352,
          "Value": 39023776,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 70,
          "Name": "internal.metrics.shuffle.write.recordsWritten",
          "Update": 2,
          "Value": 3,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 69,
          "Name": "internal.metrics.shuffle.write.bytesWritten",
          "Update": 90,
          "Value": 170,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 57,
          "Name": "internal.metrics.resultSerializationTime",
          "Update": 2,
          "Value": 3,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 55,
          "Name": "internal.metrics.resultSize",
          "Update": 1628,
          "Value": 3256,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 54,
          "Name": "internal.metrics.executorCpuTime",
          "Update": 170963000,
          "Value": 368127000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 53,
          "Name": "internal.metrics.executorRunTime",
          "Update": 378,
          "Value": 757,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 52,
          "Name": "internal.metrics.executorDeserializeCpuTime",
          "Update": 10567000,
          "Value": 21706000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 51,
          "Name": "internal.metrics.executorDeserializeTime",
          "Update": 27,
          "Value": 52,
          "Internal": true,
          "Count Failed Values": true
        }
      ]
    },
    "Task Metrics": {
      "Executor Deserialize Time": 27,
      "Executor Deserialize CPU Time": 10567000,
      "Executor Run Time": 378,
      "Executor CPU Time": 170963000,
      "Result Size": 1628,
      "JVM GC Time": 0,
      "Result Serialization Time": 2,
      "Memory Bytes Spilled": 0,
      "Disk Bytes Spilled": 0,
      "Shuffle Read Metrics": {
        "Remote Blocks Fetched": 0,
        "Local Blocks Fetched": 0,
        "Fetch Wait Time": 0,
        "Remote Bytes Read": 0,
        "Remote Bytes Read To Disk": 0,
        "Local Bytes Read": 0,
        "Total Records Read": 0
      },
      "Shuffle Write Metrics": {
        "Shuffle Bytes Written": 90,
        "Shuffle Write Time": 19888352,
        "Shuffle Records Written": 2
      },
      "Input Metrics": {
        "Bytes Read": 2250,
        "Records Read": 2
      },
      "Output Metrics": {
        "Bytes Written": 0,
        "Records Written": 0
      },
      "Updated Blocks": []
    }
  },
  {
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
      "Stage ID": 1,
      "Stage Attempt ID": 0,
      "Stage Name": "processCmd at CliDriver.java:376",
      "Number of Tasks": 2,
      "RDD Info": [
        {
          "RDD ID": 7,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"16\",\"name\":\"Exchange\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            6
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 5,
          "Name": "FileScanRDD",
          "Scope": "{\"id\":\"17\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 6,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"17\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            5
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        }
      ],
      "Parent IDs": [],
      "Details": "org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:364)\norg.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:272)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)",
      "Submission Time": 1544147164430,
      "Completion Time": 1544147164888,
      "Accumulables": [
        {
          "ID": 53,
          "Name": "internal.metrics.executorRunTime",
          "Value": 757,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 71,
          "Name": "internal.metrics.shuffle.write.writeTime",
          "Value": 39023776,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 20,
          "Name": "duration total (min, med, max)",
          "Value": "591",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 55,
          "Name": "internal.metrics.resultSize",
          "Value": 3256,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 73,
          "Name": "internal.metrics.input.recordsRead",
          "Value": 3,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 22,
          "Name": "number of output rows",
          "Value": "3",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 52,
          "Name": "internal.metrics.executorDeserializeCpuTime",
          "Value": 21706000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 70,
          "Name": "internal.metrics.shuffle.write.recordsWritten",
          "Value": 3,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 25,
          "Name": "scan time total (min, med, max)",
          "Value": "507",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 69,
          "Name": "internal.metrics.shuffle.write.bytesWritten",
          "Value": 170,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 54,
          "Name": "internal.metrics.executorCpuTime",
          "Value": 368127000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 72,
          "Name": "internal.metrics.input.bytesRead",
          "Value": 4715,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 3,
          "Name": "data size total (min, med, max)",
          "Value": "117",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 21,
          "Name": "number of output rows",
          "Value": "3",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 57,
          "Name": "internal.metrics.resultSerializationTime",
          "Value": 3,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 51,
          "Name": "internal.metrics.executorDeserializeTime",
          "Value": 52,
          "Internal": true,
          "Count Failed Values": true
        }
      ]
    }
  },
  {
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 0,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
      "Reason": "Success"
    },
    "Task Info": {
      "Task ID": 1,
      "Index": 1,
      "Attempt": 0,
      "Launch Time": 1544147164451,
      "Executor ID": "driver",
      "Host": "localhost",
      "Locality": "PROCESS_LOCAL",
      "Speculative": false,
      "Getting Result Time": 0,
      "Finish Time": 1544147164882,
      "Failed": false,
      "Killed": false,
      "Accumulables": [
        {
          "ID": 2,
          "Name": "data size total (min, med, max)",
          "Update": "47",
          "Value": "141",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 11,
          "Name": "number of output rows",
          "Update": "1",
          "Value": "3",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 15,
          "Name": "scan time total (min, med, max)",
          "Update": "254",
          "Value": "507",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 12,
          "Name": "number of output rows",
          "Update": "1",
          "Value": "3",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 10,
          "Name": "duration total (min, med, max)",
          "Update": "297",
          "Value": "594",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 48,
          "Name": "internal.metrics.input.recordsRead",
          "Update": 1,
          "Value": 3,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 47,
          "Name": "internal.metrics.input.bytesRead",
          "Update": 2343,
          "Value": 4734,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 46,
          "Name": "internal.metrics.shuffle.write.writeTime",
          "Update": 19313857,
          "Value": 40159399,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 45,
          "Name": "internal.metrics.shuffle.write.recordsWritten",
          "Update": 1,
          "Value": 3,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 44,
          "Name": "internal.metrics.shuffle.write.bytesWritten",
          "Update": 84,
          "Value": 189,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 32,
          "Name": "internal.metrics.resultSerializationTime",
          "Update": 1,
          "Value": 3,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 30,
          "Name": "internal.metrics.resultSize",
          "Update": 1628,
          "Value": 3256,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 29,
          "Name": "internal.metrics.executorCpuTime",
          "Update": 107049000,
          "Value": 214957000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 28,
          "Name": "internal.metrics.executorRunTime",
          "Update": 378,
          "Value": 757,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 27,
          "Name": "internal.metrics.executorDeserializeCpuTime",
          "Update": 9329000,
          "Value": 31478000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 26,
          "Name": "internal.metrics.executorDeserializeTime",
          "Update": 28,
          "Value": 55,
          "Internal": true,
          "Count Failed Values": true
        }
      ]
    },
    "Task Metrics": {
      "Executor Deserialize Time": 28,
      "Executor Deserialize CPU Time": 9329000,
      "Executor Run Time": 378,
      "Executor CPU Time": 107049000,
      "Result Size": 1628,
      "JVM GC Time": 0,
      "Result Serialization Time": 1,
      "Memory Bytes Spilled": 0,
      "Disk Bytes Spilled": 0,
      "Shuffle Read Metrics": {
        "Remote Blocks Fetched": 0,
        "Local Blocks Fetched": 0,
        "Fetch Wait Time": 0,
        "Remote Bytes Read": 0,
        "Remote Bytes Read To Disk": 0,
        "Local Bytes Read": 0,
        "Total Records Read": 0
      },
      "Shuffle Write Metrics": {
        "Shuffle Bytes Written": 84,
        "Shuffle Write Time": 19313857,
        "Shuffle Records Written": 1
      },
      "Input Metrics": {
        "Bytes Read": 2343,
        "Records Read": 1
      },
      "Output Metrics": {
        "Bytes Written": 0,
        "Records Written": 0
      },
      "Updated Blocks": []
    }
  },
  {
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
      "Stage ID": 0,
      "Stage Attempt ID": 0,
      "Stage Name": "processCmd at CliDriver.java:376",
      "Number of Tasks": 2,
      "RDD Info": [
        {
          "RDD ID": 2,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"7\",\"name\":\"Exchange\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            1
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 1,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"8\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            0
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 0,
          "Name": "FileScanRDD",
          "Scope": "{\"id\":\"8\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        }
      ],
      "Parent IDs": [],
      "Details": "org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:364)\norg.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:272)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)",
      "Submission Time": 1544147164396,
      "Completion Time": 1544147164893,
      "Accumulables": [
        {
          "ID": 32,
          "Name": "internal.metrics.resultSerializationTime",
          "Value": 3,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 26,
          "Name": "internal.metrics.executorDeserializeTime",
          "Value": 55,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 44,
          "Name": "internal.metrics.shuffle.write.bytesWritten",
          "Value": 189,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 11,
          "Name": "number of output rows",
          "Value": "3",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 29,
          "Name": "internal.metrics.executorCpuTime",
          "Value": 214957000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 47,
          "Name": "internal.metrics.input.bytesRead",
          "Value": 4734,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 2,
          "Name": "data size total (min, med, max)",
          "Value": "141",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 46,
          "Name": "internal.metrics.shuffle.write.writeTime",
          "Value": 40159399,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 10,
          "Name": "duration total (min, med, max)",
          "Value": "594",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 28,
          "Name": "internal.metrics.executorRunTime",
          "Value": 757,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 45,
          "Name": "internal.metrics.shuffle.write.recordsWritten",
          "Value": 3,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 27,
          "Name": "internal.metrics.executorDeserializeCpuTime",
          "Value": 31478000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 48,
          "Name": "internal.metrics.input.recordsRead",
          "Value": 3,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 12,
          "Name": "number of output rows",
          "Value": "3",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 30,
          "Name": "internal.metrics.resultSize",
          "Value": 3256,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 15,
          "Name": "scan time total (min, med, max)",
          "Value": "507",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        }
      ]
    }
  },
  {
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
      "Stage ID": 2,
      "Stage Attempt ID": 0,
      "Stage Name": "processCmd at CliDriver.java:376",
      "Number of Tasks": 2,
      "RDD Info": [
        {
          "RDD ID": 12,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"21\",\"name\":\"mapPartitionsInternal\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            11
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 4,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"4\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            3
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 9,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"13\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            8
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 8,
          "Name": "ShuffledRowRDD",
          "Scope": "{\"id\":\"16\",\"name\":\"Exchange\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            7
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 10,
          "Name": "ZippedPartitionsRDD2",
          "Scope": "{\"id\":\"0\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            4,
            9
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 11,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"0\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            10
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 3,
          "Name": "ShuffledRowRDD",
          "Scope": "{\"id\":\"7\",\"name\":\"Exchange\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            2
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        }
      ],
      "Parent IDs": [
        0,
        1
      ],
      "Details": "org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:364)\norg.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:272)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)",
      "Submission Time": 1544147164898,
      "Accumulables": []
    },
    "Properties": {
      "spark.rdd.scope.noOverride": "true",
      "spark.rdd.scope": "{\"id\":\"22\",\"name\":\"collect\"}",
      "spark.sql.execution.id": "0",
      "spark.job.description": "select p.id, p.name, gp.school from person p join graduate_program gp on p.graduate_program = gp.id"
    }
  },
  {
    "Event": "SparkListenerTaskStart",
    "Stage ID": 2,
    "Stage Attempt ID": 0,
    "Task Info": {
      "Task ID": 4,
      "Index": 0,
      "Attempt": 0,
      "Launch Time": 1544147164907,
      "Executor ID": "driver",
      "Host": "localhost",
      "Locality": "ANY",
      "Speculative": false,
      "Getting Result Time": 0,
      "Finish Time": 0,
      "Failed": false,
      "Killed": false,
      "Accumulables": []
    }
  },
  {
    "Event": "SparkListenerTaskStart",
    "Stage ID": 2,
    "Stage Attempt ID": 0,
    "Task Info": {
      "Task ID": 5,
      "Index": 1,
      "Attempt": 0,
      "Launch Time": 1544147164910,
      "Executor ID": "driver",
      "Host": "localhost",
      "Locality": "ANY",
      "Speculative": false,
      "Getting Result Time": 0,
      "Finish Time": 0,
      "Failed": false,
      "Killed": false,
      "Accumulables": []
    }
  },
  {
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 2,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
      "Reason": "Success"
    },
    "Task Info": {
      "Task ID": 4,
      "Index": 0,
      "Attempt": 0,
      "Launch Time": 1544147164907,
      "Executor ID": "driver",
      "Host": "localhost",
      "Locality": "ANY",
      "Speculative": false,
      "Getting Result Time": 0,
      "Finish Time": 1544147165006,
      "Failed": false,
      "Killed": false,
      "Accumulables": [
        {
          "ID": 4,
          "Name": "duration total (min, med, max)",
          "Update": "4",
          "Value": "3",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 8,
          "Name": "peak memory total (min, med, max)",
          "Update": "65535",
          "Value": "65534",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 6,
          "Name": "duration total (min, med, max)",
          "Update": "66",
          "Value": "65",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 93,
          "Name": "internal.metrics.shuffle.read.recordsRead",
          "Update": 0,
          "Value": 0,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 92,
          "Name": "internal.metrics.shuffle.read.fetchWaitTime",
          "Update": 0,
          "Value": 0,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 91,
          "Name": "internal.metrics.shuffle.read.localBytesRead",
          "Update": 80,
          "Value": 80,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 90,
          "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
          "Update": 0,
          "Value": 0,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 89,
          "Name": "internal.metrics.shuffle.read.remoteBytesRead",
          "Update": 0,
          "Value": 0,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 88,
          "Name": "internal.metrics.shuffle.read.localBlocksFetched",
          "Update": 1,
          "Value": 1,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 87,
          "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
          "Update": 0,
          "Value": 0,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 85,
          "Name": "internal.metrics.peakExecutionMemory",
          "Update": 65536,
          "Value": 65536,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 82,
          "Name": "internal.metrics.resultSerializationTime",
          "Update": 1,
          "Value": 1,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 80,
          "Name": "internal.metrics.resultSize",
          "Update": 3465,
          "Value": 3465,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 79,
          "Name": "internal.metrics.executorCpuTime",
          "Update": 57804000,
          "Value": 57804000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 78,
          "Name": "internal.metrics.executorRunTime",
          "Update": 86,
          "Value": 86,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 77,
          "Name": "internal.metrics.executorDeserializeCpuTime",
          "Update": 6553000,
          "Value": 6553000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 76,
          "Name": "internal.metrics.executorDeserializeTime",
          "Update": 7,
          "Value": 7,
          "Internal": true,
          "Count Failed Values": true
        }
      ]
    },
    "Task Metrics": {
      "Executor Deserialize Time": 7,
      "Executor Deserialize CPU Time": 6553000,
      "Executor Run Time": 86,
      "Executor CPU Time": 57804000,
      "Result Size": 3465,
      "JVM GC Time": 0,
      "Result Serialization Time": 1,
      "Memory Bytes Spilled": 0,
      "Disk Bytes Spilled": 0,
      "Shuffle Read Metrics": {
        "Remote Blocks Fetched": 0,
        "Local Blocks Fetched": 1,
        "Fetch Wait Time": 0,
        "Remote Bytes Read": 0,
        "Remote Bytes Read To Disk": 0,
        "Local Bytes Read": 80,
        "Total Records Read": 0
      },
      "Shuffle Write Metrics": {
        "Shuffle Bytes Written": 0,
        "Shuffle Write Time": 0,
        "Shuffle Records Written": 0
      },
      "Input Metrics": {
        "Bytes Read": 0,
        "Records Read": 0
      },
      "Output Metrics": {
        "Bytes Written": 0,
        "Records Written": 0
      },
      "Updated Blocks": []
    }
  },
  {
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 2,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
      "Reason": "Success"
    },
    "Task Info": {
      "Task ID": 5,
      "Index": 1,
      "Attempt": 0,
      "Launch Time": 1544147164910,
      "Executor ID": "driver",
      "Host": "localhost",
      "Locality": "ANY",
      "Speculative": false,
      "Getting Result Time": 0,
      "Finish Time": 1544147165016,
      "Failed": false,
      "Killed": false,
      "Accumulables": [
        {
          "ID": 5,
          "Name": "number of output rows",
          "Update": "3",
          "Value": "3",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 4,
          "Name": "duration total (min, med, max)",
          "Update": "17",
          "Value": "20",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 18,
          "Name": "peak memory total (min, med, max)",
          "Update": "2162687",
          "Value": "2162685",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 16,
          "Name": "duration total (min, med, max)",
          "Update": "38",
          "Value": "36",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 8,
          "Name": "peak memory total (min, med, max)",
          "Update": "2162687",
          "Value": "2228221",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 6,
          "Name": "duration total (min, med, max)",
          "Update": "68",
          "Value": "133",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 93,
          "Name": "internal.metrics.shuffle.read.recordsRead",
          "Update": 5,
          "Value": 5,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 92,
          "Name": "internal.metrics.shuffle.read.fetchWaitTime",
          "Update": 0,
          "Value": 0,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 91,
          "Name": "internal.metrics.shuffle.read.localBytesRead",
          "Update": 279,
          "Value": 359,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 90,
          "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
          "Update": 0,
          "Value": 0,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 89,
          "Name": "internal.metrics.shuffle.read.remoteBytesRead",
          "Update": 0,
          "Value": 0,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 88,
          "Name": "internal.metrics.shuffle.read.localBlocksFetched",
          "Update": 3,
          "Value": 4,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 87,
          "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
          "Update": 0,
          "Value": 0,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 85,
          "Name": "internal.metrics.peakExecutionMemory",
          "Update": 4325376,
          "Value": 4390912,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 80,
          "Name": "internal.metrics.resultSize",
          "Update": 3534,
          "Value": 6999,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 79,
          "Name": "internal.metrics.executorCpuTime",
          "Update": 71882000,
          "Value": 129686000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 78,
          "Name": "internal.metrics.executorRunTime",
          "Update": 99,
          "Value": 185,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 77,
          "Name": "internal.metrics.executorDeserializeCpuTime",
          "Update": 6467000,
          "Value": 13020000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 76,
          "Name": "internal.metrics.executorDeserializeTime",
          "Update": 6,
          "Value": 13,
          "Internal": true,
          "Count Failed Values": true
        }
      ]
    },
    "Task Metrics": {
      "Executor Deserialize Time": 6,
      "Executor Deserialize CPU Time": 6467000,
      "Executor Run Time": 99,
      "Executor CPU Time": 71882000,
      "Result Size": 3534,
      "JVM GC Time": 0,
      "Result Serialization Time": 0,
      "Memory Bytes Spilled": 0,
      "Disk Bytes Spilled": 0,
      "Shuffle Read Metrics": {
        "Remote Blocks Fetched": 0,
        "Local Blocks Fetched": 3,
        "Fetch Wait Time": 0,
        "Remote Bytes Read": 0,
        "Remote Bytes Read To Disk": 0,
        "Local Bytes Read": 279,
        "Total Records Read": 5
      },
      "Shuffle Write Metrics": {
        "Shuffle Bytes Written": 0,
        "Shuffle Write Time": 0,
        "Shuffle Records Written": 0
      },
      "Input Metrics": {
        "Bytes Read": 0,
        "Records Read": 0
      },
      "Output Metrics": {
        "Bytes Written": 0,
        "Records Written": 0
      },
      "Updated Blocks": []
    }
  },
  {
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
      "Stage ID": 2,
      "Stage Attempt ID": 0,
      "Stage Name": "processCmd at CliDriver.java:376",
      "Number of Tasks": 2,
      "RDD Info": [
        {
          "RDD ID": 12,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"21\",\"name\":\"mapPartitionsInternal\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            11
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 4,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"4\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            3
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 9,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"13\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            8
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 8,
          "Name": "ShuffledRowRDD",
          "Scope": "{\"id\":\"16\",\"name\":\"Exchange\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            7
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 10,
          "Name": "ZippedPartitionsRDD2",
          "Scope": "{\"id\":\"0\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            4,
            9
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 11,
          "Name": "MapPartitionsRDD",
          "Scope": "{\"id\":\"0\",\"name\":\"WholeStageCodegen\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            10
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        },
        {
          "RDD ID": 3,
          "Name": "ShuffledRowRDD",
          "Scope": "{\"id\":\"7\",\"name\":\"Exchange\"}",
          "Callsite": "processCmd at CliDriver.java:376",
          "Parent IDs": [
            2
          ],
          "Storage Level": {
            "Use Disk": false,
            "Use Memory": false,
            "Deserialized": false,
            "Replication": 1
          },
          "Number of Partitions": 2,
          "Number of Cached Partitions": 0,
          "Memory Size": 0,
          "Disk Size": 0
        }
      ],
      "Parent IDs": [
        0,
        1
      ],
      "Details": "org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:364)\norg.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:272)\norg.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)",
      "Submission Time": 1544147164898,
      "Completion Time": 1544147165017,
      "Accumulables": [
        {
          "ID": 92,
          "Name": "internal.metrics.shuffle.read.fetchWaitTime",
          "Value": 0,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 77,
          "Name": "internal.metrics.executorDeserializeCpuTime",
          "Value": 13020000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 8,
          "Name": "peak memory total (min, med, max)",
          "Value": "2228221",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 80,
          "Name": "internal.metrics.resultSize",
          "Value": 6999,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 89,
          "Name": "internal.metrics.shuffle.read.remoteBytesRead",
          "Value": 0,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 5,
          "Name": "number of output rows",
          "Value": "3",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 82,
          "Name": "internal.metrics.resultSerializationTime",
          "Value": 1,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 91,
          "Name": "internal.metrics.shuffle.read.localBytesRead",
          "Value": 359,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 4,
          "Name": "duration total (min, med, max)",
          "Value": "20",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 85,
          "Name": "internal.metrics.peakExecutionMemory",
          "Value": 4390912,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 76,
          "Name": "internal.metrics.executorDeserializeTime",
          "Value": 13,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 16,
          "Name": "duration total (min, med, max)",
          "Value": "36",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 79,
          "Name": "internal.metrics.executorCpuTime",
          "Value": 129686000,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 88,
          "Name": "internal.metrics.shuffle.read.localBlocksFetched",
          "Value": 4,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 87,
          "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
          "Value": 0,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 78,
          "Name": "internal.metrics.executorRunTime",
          "Value": 185,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 90,
          "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
          "Value": 0,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 18,
          "Name": "peak memory total (min, med, max)",
          "Value": "2162685",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        },
        {
          "ID": 93,
          "Name": "internal.metrics.shuffle.read.recordsRead",
          "Value": 5,
          "Internal": true,
          "Count Failed Values": true
        },
        {
          "ID": 6,
          "Name": "duration total (min, med, max)",
          "Value": "133",
          "Internal": true,
          "Count Failed Values": true,
          "Metadata": "sql"
        }
      ]
    }
  },
  {
    "Event": "SparkListenerJobEnd",
    "Job ID": 0,
    "Completion Time": 1544147165021,
    "Job Result": {
      "Result": "JobSucceeded"
    }
  },
  {
    "Event": "org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd",
    "executionId": 0,
    "time": 1544147165033
  },
  {
    "Event": "SparkListenerApplicationEnd",
    "Timestamp": 1544147181732
  }
]